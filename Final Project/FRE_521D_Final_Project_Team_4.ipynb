{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d12d295-8305-424f-9c95-f83b8516ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas statsmodels pymysql sqlalchemy ipython-sql --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3624467-356f-491f-b6cc-1ab961aa10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from datetime import datetime, timezone\n",
    "import warnings\n",
    "import re\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import requests\n",
    "from sqlalchemy import text\n",
    "from typing import Optional, Dict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173352b-4d6f-4521-b17c-3b0ea9ebb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection configuration\n",
    "# Update these values if your setup is different\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",      \n",
    "    \"port\": 3306,\n",
    "    \"user\": \"mfre521d_user\",\n",
    "    \"password\": \"mfre521d_user_pw\",\n",
    "    \"database\": \"mfre521d\",\n",
    "}\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"Create and return a database connection.\"\"\"\n",
    "    return mysql.connector.connect(**DB_CONFIG)\n",
    "\n",
    "def read_table(query):\n",
    "    \"\"\"Execute a SQL query and return results as DataFrame.\"\"\"\n",
    "    conn = get_connection()\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn)\n",
    "        return df\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    conn = get_connection()\n",
    "    print(\"Connected to MySQL successfully!\")\n",
    "    conn.close()\n",
    "except Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure your Docker container is running.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38751b7b-bfa0-4d0d-955d-cc788713d4da",
   "metadata": {},
   "source": [
    "---\n",
    "### Part A\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                     SOURCE FILES / APIs                     │\n",
    "│             country_centroids.csv source file               │\n",
    "│     https://open-meteo.com/en/docs/historical-weather-api   │\n",
    "└─────────────────────────┬───────────────────────────────────┘\n",
    "                          │ Extract (no changes)\n",
    "                          ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                      RAW LAYER                              │\n",
    "│   - Exact copy of source                                    │\n",
    "│   - All data as strings                                     │\n",
    "│   - Add: meta data, extraction timestamp, row number        │\n",
    "│   - Never modify this layer                                 │\n",
    "└─────────────────────────┬───────────────────────────────────┘\n",
    "                          │ Transform\n",
    "                          ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    CLEANED LAYER                            │\n",
    "│   - Correct data types                                      │\n",
    "│   - Standardized formats                                    │\n",
    "│   - Nulls handled consistently                              │\n",
    "│   - Validated                                               │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "                          │ Load \n",
    "                          ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    CLEANED LAYER                            │\n",
    "│   - weather_daily                                           │\n",
    "│   - weather_daily_clean                                     │\n",
    "│   - Inserts, commits, errors                                │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8231a-1c6a-4389-b84f-aeeceddedea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read countries table\n",
    "df_countries = read_table(\"SELECT * FROM countries\")\n",
    "print(f\"Countries: {len(df_countries)} rows\")\n",
    "\n",
    "# Read crop_production table\n",
    "df_crops_clean = read_table(\"SELECT * FROM crop_production\")\n",
    "print(f\"Crop Production: {len(df_crops_clean)} rows\")\n",
    "\n",
    "# Read temperature_anomalies table\n",
    "df_temp_clean = read_table(\"SELECT * FROM temperature_anomalies\")\n",
    "print(f\"Temperature Anomalies: {len(df_temp_clean)} rows\")\n",
    "\n",
    "print(\"\\nData loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adacc3b0-d81f-42ed-878f-628cca1be43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample of each table\n",
    "print(\"=\" * 60)\n",
    "print(\"COUNTRIES TABLE\")\n",
    "print(\"=\" * 60)\n",
    "df_countries.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0c60b-9fb6-4439-96a9-7ec689054eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CROP PRODUCTION TABLE\")\n",
    "print(\"=\" * 60)\n",
    "df_crops_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0247f1-47e3-44c3-b130-30271a5b57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEMPERATURE ANOMALIES TABLE\")\n",
    "print(\"=\" * 60)\n",
    "df_temp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3ddc4-e6d3-4a4b-8360-fe4553f56e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types\n",
    "print(df_crops_clean.dtypes)\n",
    "# Print info (includes non-null counts)\n",
    "df_crops_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acf865-a3cf-4fe4-b8e9-532caf4a650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types\n",
    "print(df_temp_clean.dtypes)\n",
    "\n",
    "# Print info\n",
    "df_temp_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c3de4-ad33-4757-8a2d-668f670e04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'december' to 'dec' \n",
    "df_temp = df_temp_clean.rename(columns={'december': 'dec'})\n",
    "df_temp.info()\n",
    "\n",
    "df_temp.to_csv(\"temperature_anomalies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827f88d-05bb-4b31-9bc7-5fc3d9eb3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ---- Part E: Data Lineage ----\n",
    "\n",
    "def create_lineage_readme(source_file, raw_file, cleaned_file, transformations):\n",
    "    readme = f\"\"\"# Data Lineage Documentation\n",
    "\n",
    "Generated: {datetime.now().isoformat()}\n",
    "\n",
    "## Source\n",
    "- File: {source_file}\n",
    "\n",
    "## Raw Layer\n",
    "- File: {raw_file}\n",
    "- Contains exact copy of source with metadata columns added\n",
    "\n",
    "## Cleaned Layer\n",
    "- File: {cleaned_file}\n",
    "\n",
    "## Transformations Applied\n",
    "\"\"\"\n",
    "    for t in transformations:\n",
    "        readme += f\"- {t}\\n\"\n",
    "    return readme\n",
    "\n",
    "\n",
    "# Transformations Applied for crop production data\n",
    "transformations_crop = [\n",
    "    \"Converted all column names to lowercase\",\n",
    "    \"Stripped whitespace from text columns\",\n",
    "    \"Converted Year from string to integer\",\n",
    "    \"Replaced missing codes (NA, .., -, N/A) with NULL\",\n",
    "    \"Created a country_id column by mapping country names to IDs\",\n",
    "    \"Inserted cleaned data into MySQL crop_production table\",\n",
    "]\n",
    "\n",
    "readme_crop = create_lineage_readme(\n",
    "    \"crop_production_1990_2023.csv\",\n",
    "    \"Not saved, dataframe only\",\n",
    "    \"Not saved, dataframe only\",\n",
    "    transformations_crop\n",
    ")\n",
    "\n",
    "# Transformations Applied for temperature anomalies data\n",
    "transformations_temp = [\n",
    "    \"Converted all column names to lowercase\",\n",
    "    \"Stripped whitespace from text columns\",\n",
    "    \"Created country_std for mapping to countries table\",\n",
    "    \"Converted numeric columns to float (handled European decimals)\",\n",
    "    \"Converted Year from string to integer\",\n",
    "    \"Converted monthly anomaly columns to float (handled European decimals)\",\n",
    "    \"Renamed month columns to match DB schema (e.g., 'january' to 'jan')\",\n",
    "    \"Replaced missing codes (NA, .., -, N/A) with NULL\",\n",
    "    \"Inserted cleaned data into MySQL temperature_anomalies table\",\n",
    "]\n",
    "\n",
    "readme_temp = create_lineage_readme(\n",
    "    \"temperature_anomalies_1990_2023.csv\",\n",
    "    \"Not saved, dataframe only\",\n",
    "    \"Not saved, dataframe only\",\n",
    "    transformations_temp\n",
    ")\n",
    "\n",
    "# Create directory FIRST\n",
    "Path(\"data/cleaned\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#  Write files ONCE\n",
    "with open(\"data/cleaned/README_CROP.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_crop)\n",
    "\n",
    "with open(\"data/cleaned/README_TEMP.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_temp)\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"- data/cleaned/README_CROP.md\")\n",
    "print(\"- data/cleaned/README_TEMP.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd6185-3cc1-4fde-ab28-807ef2609a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"data/ exists?\", (Path.cwd() / \"data\").exists())\n",
    "print(\"Datasets/ exists?\", (Path.cwd() / \"Datasets\").exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31a780-e06b-4d09-a6ce-b1159e58f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Two: Implement a Python-based ETL pipeline that extracts weather data from the Open-Meteo API and loads it into your MySQL database.\n",
    "# API Configuration\n",
    "API_BASE_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "RATE_LIMIT_DELAY = 5  # seconds between requests (minimum per assignment)\n",
    "MAX_RETRIES = 3\n",
    "BACKOFF_FACTOR = 2  # exponential backoff multiplier\n",
    "\n",
    "# Data extraction parameters\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = \"2023-12-31\"\n",
    "\n",
    "# Weather variables to extract \n",
    "WEATHER_VARIABLES = [\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"precipitation_sum\",\n",
    "    \"rain_sum\",\n",
    "    \"et0_fao_evapotranspiration\"\n",
    "]\n",
    "\n",
    "print(\"Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b8ce4-5a4b-416b-bd1f-862c49a6619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part F: Country centroids for API requests\n",
    "# These are approximate geographic centers of each country\n",
    "\n",
    "COUNTRY_CENTROIDS = {\n",
    "    # North America\n",
    "    'USA': {'name': 'United States', 'lat': 39.8283, 'lon': -98.5795, 'hemisphere': 'Northern'},\n",
    "    'CAN': {'name': 'Canada', 'lat': 56.1304, 'lon': -106.3468, 'hemisphere': 'Northern'},\n",
    "    'MEX': {'name': 'Mexico', 'lat': 23.6345, 'lon': -102.5528, 'hemisphere': 'Northern'},\n",
    "    \n",
    "    # South America\n",
    "    'BRA': {'name': 'Brazil', 'lat': -14.2350, 'lon': -51.9253, 'hemisphere': 'Southern'},\n",
    "    'ARG': {'name': 'Argentina', 'lat': -38.4161, 'lon': -63.6167, 'hemisphere': 'Southern'},\n",
    "    \n",
    "    # Europe\n",
    "    'DEU': {'name': 'Germany', 'lat': 51.1657, 'lon': 10.4515, 'hemisphere': 'Northern'},\n",
    "    'FRA': {'name': 'France', 'lat': 46.2276, 'lon': 2.2137, 'hemisphere': 'Northern'},\n",
    "    'GBR': {'name': 'United Kingdom', 'lat': 55.3781, 'lon': -3.4360, 'hemisphere': 'Northern'},\n",
    "    'UKR': {'name': 'Ukraine', 'lat': 48.3794, 'lon': 31.1656, 'hemisphere': 'Northern'},\n",
    "    'RUS': {'name': 'Russia', 'lat': 55.7558, 'lon': 37.6173, 'hemisphere': 'Northern'},\n",
    "    'TUR': {'name': 'Turkey', 'lat': 38.9637, 'lon': 35.2433, 'hemisphere': 'Northern'},\n",
    "    \n",
    "    # Asia\n",
    "    'CHN': {'name': 'China', 'lat': 35.8617, 'lon': 104.1954, 'hemisphere': 'Northern'},\n",
    "    'IND': {'name': 'India', 'lat': 20.5937, 'lon': 78.9629, 'hemisphere': 'Northern'},\n",
    "    'JPN': {'name': 'Japan', 'lat': 36.2048, 'lon': 138.2529, 'hemisphere': 'Northern'},\n",
    "    'KOR': {'name': 'South Korea', 'lat': 35.9078, 'lon': 127.7669, 'hemisphere': 'Northern'},\n",
    "    'IDN': {'name': 'Indonesia', 'lat': -0.7893, 'lon': 113.9213, 'hemisphere': 'Southern'},\n",
    "    'THA': {'name': 'Thailand', 'lat': 15.8700, 'lon': 100.9925, 'hemisphere': 'Northern'},\n",
    "    'VNM': {'name': 'Vietnam', 'lat': 14.0583, 'lon': 108.2772, 'hemisphere': 'Northern'},\n",
    "    'PAK': {'name': 'Pakistan', 'lat': 30.3753, 'lon': 69.3451, 'hemisphere': 'Northern'},\n",
    "    'BGD': {'name': 'Bangladesh', 'lat': 23.6850, 'lon': 90.3563, 'hemisphere': 'Northern'},\n",
    "    'MMR': {'name': 'Myanmar', 'lat': 21.9162, 'lon': 95.9560, 'hemisphere': 'Northern'},\n",
    "    'PHL': {'name': 'Philippines', 'lat': 12.8797, 'lon': 121.7740, 'hemisphere': 'Northern'},\n",
    "    'NPL': {'name': 'Nepal', 'lat': 28.3949, 'lon': 84.1240, 'hemisphere': 'Northern'},\n",
    "    \n",
    "    # Africa\n",
    "    'EGY': {'name': 'Egypt', 'lat': 26.8206, 'lon': 30.8025, 'hemisphere': 'Northern'},\n",
    "    'NGA': {'name': 'Nigeria', 'lat': 9.0820, 'lon': 8.6753, 'hemisphere': 'Northern'},\n",
    "    'ETH': {'name': 'Ethiopia', 'lat': 9.1450, 'lon': 40.4897, 'hemisphere': 'Northern'},\n",
    "    'ZAF': {'name': 'South Africa', 'lat': -30.5595, 'lon': 22.9375, 'hemisphere': 'Southern'},\n",
    "    'KEN': {'name': 'Kenya', 'lat': -0.0236, 'lon': 37.9062, 'hemisphere': 'Southern'},\n",
    "    'TZA': {'name': 'Tanzania', 'lat': -6.3690, 'lon': 34.8888, 'hemisphere': 'Southern'},\n",
    "    'MAR': {'name': 'Morocco', 'lat': 31.7917, 'lon': -7.0926, 'hemisphere': 'Northern'},\n",
    "    'UGA': {'name': 'Uganda', 'lat': 1.3733, 'lon': 32.2903, 'hemisphere': 'Northern'},\n",
    "    'MWI': {'name': 'Malawi', 'lat': -13.2543, 'lon': 34.3015, 'hemisphere': 'Southern'},\n",
    "    'MLI': {'name': 'Mali', 'lat': 17.5707, 'lon': -3.9962, 'hemisphere': 'Northern'},\n",
    "    \n",
    "    # Oceania\n",
    "    'AUS': {'name': 'Australia', 'lat': -25.2744, 'lon': 133.7751, 'hemisphere': 'Southern'},\n",
    "}\n",
    "\n",
    "print(f\"Loaded {len(COUNTRY_CENTROIDS)} country centroids.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194f02d-7f8b-4ed6-b1d2-55d8412befc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save country centroids to CSV for reference\n",
    "centroids_df = pd.DataFrame([\n",
    "    {'iso3_code': k, 'country_name': v['name'], 'latitude': v['lat'], \n",
    "     'longitude': v['lon'], 'hemisphere': v['hemisphere']}\n",
    "    for k, v in COUNTRY_CENTROIDS.items()\n",
    "])\n",
    "\n",
    "centroids_df.to_csv('country_centroids.csv', index=False)\n",
    "print(\"Country centroids saved to country_centroids.csv\")\n",
    "centroids_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34d8c9-b569-4e3d-8f2b-2bedf3ef7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "def setup_logging(log_file='etl_pipeline.log'):\n",
    "    \"\"\"\n",
    "    Configure logging for the ETL pipeline.\n",
    "    Logs to both file and console.\n",
    "    \"\"\"\n",
    "    # Remove existing handlers\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s | %(levelname)-8s | %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_logging()\n",
    "logger.info(\"Logging initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c85e4e-24a5-4a6a-98ec-3c1aef20cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part G: Implement rate limiting to avoid exceeding API quotas (minimum 5 second delay between requests)\n",
    "class RateLimiter:\n",
    "    \"\"\"\n",
    "    Rate limiter to ensure minimum delay between API requests.\n",
    "    Implements adaptive delay on rate limit errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_delay: float = 5.0):\n",
    "        self.min_delay = min_delay\n",
    "        self.current_delay = min_delay\n",
    "        self.last_request_time = 0\n",
    "        self.request_count = 0\n",
    "    \n",
    "    def wait(self):\n",
    "        \"\"\"Wait if needed to respect rate limit.\"\"\"\n",
    "        elapsed = time.time() - self.last_request_time\n",
    "        if elapsed < self.current_delay:\n",
    "            sleep_time = self.current_delay - elapsed\n",
    "            time.sleep(sleep_time)\n",
    "        self.last_request_time = time.time()\n",
    "        self.request_count += 1\n",
    "    \n",
    "    def increase_delay(self):\n",
    "        \"\"\"Increase delay on rate limit error.\"\"\"\n",
    "        self.current_delay = min(self.current_delay * 2, 30.0)\n",
    "        logger.warning(f\"Rate limit hit, increased delay to {self.current_delay}s\")\n",
    "    \n",
    "    def reset_delay(self):\n",
    "        \"\"\"Reset delay after successful request.\"\"\"\n",
    "        self.current_delay = self.min_delay\n",
    "\n",
    "\n",
    "rate_limiter = RateLimiter(min_delay=RATE_LIMIT_DELAY)\n",
    "print(f\"Rate limiter initialized with {RATE_LIMIT_DELAY}s minimum delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c42d6-c7c5-488d-a857-0537bc84f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part H: Handle API errors gracefully with retry logic (at least 3 retries with exponential backoff)\n",
    "def fetch_weather_data(iso3_code: str, lat: float, lon: float,\n",
    "                       start_date: str, end_date: str,\n",
    "                       max_retries: int = MAX_RETRIES) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch weather data from Open-Meteo API with retry logic + exponential backoff.\n",
    "    Enforces >= 5s delay between requests via RateLimiter.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": \",\".join(WEATHER_VARIABLES),\n",
    "        \"timezone\": \"UTC\"\n",
    "    }\n",
    "\n",
    "    retryable_codes = {429, 500, 502, 503, 504}\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            rate_limiter.wait()\n",
    "\n",
    "            # Make request\n",
    "            response = requests.get(API_BASE_URL, params=params, timeout=30)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                rate_limiter.reset_delay()\n",
    "                logger.info(f\"{iso3_code}: Success\")\n",
    "                return response.json()\n",
    "\n",
    "            if response.status_code in retryable_codes:\n",
    "                if response.status_code == 429:\n",
    "                    rate_limiter.increase_delay()\n",
    "\n",
    "                wait_time = (BACKOFF_FACTOR ** (attempt - 1)) + random.random()\n",
    "                logger.warning(\n",
    "                    f\"{iso3_code}: HTTP {response.status_code}, retry {attempt}/{max_retries} in {wait_time:.1f}s\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "\n",
    "            logger.error(f\"{iso3_code}: HTTP {response.status_code}, not retrying\")\n",
    "            return None\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            wait_time = (BACKOFF_FACTOR ** (attempt - 1)) + random.random()\n",
    "            logger.warning(f\"{iso3_code}: Timeout, retry {attempt}/{max_retries} in {wait_time:.1f}s\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"{iso3_code}: Request failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    logger.error(f\"{iso3_code}: All {max_retries} retries exhausted\")\n",
    "    return None\n",
    "print(\"Fetch function defined with retry logic and exponential backoff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a60f5-bdc0-4cb4-94d0-8ac525fe1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part J: Logging all extraction activities\n",
    "\n",
    "def transform_weather_data(json_data, country_name, logger=None):\n",
    "    \"\"\"\n",
    "    Transform Open-Meteo daily JSON into normalized rows for WEATHER_VARIABLES table.\n",
    "    Returns a list of daily records (dicts).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        daily = json_data[\"daily\"]\n",
    "        dates = daily[\"time\"]\n",
    "\n",
    "        tmax = daily.get(\"temperature_2m_max\", [])\n",
    "        tmin = daily.get(\"temperature_2m_min\", [])\n",
    "        tmean = daily.get(\"temperature_2m_mean\", [])\n",
    "        prcp = daily.get(\"precipitation_sum\", [])\n",
    "        rain = daily.get(\"rain_sum\", [])\n",
    "        et0  = daily.get(\"et0_fao_evapotranspiration\", [])\n",
    "\n",
    "        rows = []\n",
    "        for i, d in enumerate(dates):\n",
    "            rows.append({\n",
    "                \"country_name\": country_name,\n",
    "                \"date\": d,\n",
    "\n",
    "                \"temperature_2m_mean\": tmean[i] if i < len(tmean) else None,\n",
    "                \"temperature_2m_max\":  tmax[i]  if i < len(tmax)  else None,\n",
    "                \"temperature_2m_min\":  tmin[i]  if i < len(tmin)  else None,\n",
    "                \"precipitation_sum\":   prcp[i]  if i < len(prcp)  else None,\n",
    "                \"rain_sum\":            rain[i]  if i < len(rain)  else None,\n",
    "                \"et0_fao_evapotranspiration\": et0[i] if i < len(et0) else None,\n",
    "            })\n",
    "\n",
    "        return rows\n",
    "\n",
    "    except KeyError as e:\n",
    "        if logger:\n",
    "            logger.error(f\"{country_name}: Missing key in JSON data: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717051eb-9fae-4c14-b3bd-471c7a06246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the upsert function\n",
    "\n",
    "def upsert_daily_weather(rows, logger=None):\n",
    "    \"\"\"\n",
    "    Loads transformed weather records into the daily_weather table (MySQL).\n",
    "    Uses UPSERT on (country_name, date).\n",
    "    \"\"\"\n",
    "    if not rows:\n",
    "        return\n",
    "\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO daily_weather (\n",
    "        country_name, date,\n",
    "        temperature_2m_mean, temperature_2m_max, temperature_2m_min,\n",
    "        precipitation_sum, rain_sum, et0_fao_evapotranspiration\n",
    "    )\n",
    "    VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        temperature_2m_mean = VALUES(temperature_2m_mean),\n",
    "        temperature_2m_max  = VALUES(temperature_2m_max),\n",
    "        temperature_2m_min  = VALUES(temperature_2m_min),\n",
    "        precipitation_sum   = VALUES(precipitation_sum),\n",
    "        rain_sum            = VALUES(rain_sum),\n",
    "        et0_fao_evapotranspiration = VALUES(et0_fao_evapotranspiration),\n",
    "        updated_at = CURRENT_TIMESTAMP;\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    values = [\n",
    "        (\n",
    "            r.get(\"country_name\"),\n",
    "            r.get(\"date\"),\n",
    "            r.get(\"temperature_2m_mean\"),\n",
    "            r.get(\"temperature_2m_max\"),\n",
    "            r.get(\"temperature_2m_min\"),\n",
    "            r.get(\"precipitation_sum\"),\n",
    "            r.get(\"rain_sum\"),\n",
    "            r.get(\"et0_fao_evapotranspiration\"),\n",
    "        )\n",
    "        for r in rows\n",
    "    ]\n",
    "\n",
    "    conn = get_connection()\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.executemany(sql, values)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        if logger:\n",
    "            logger.error(f\"Failed to load data: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e8160-28f7-43bb-8258-802ad7c23e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector, time\n",
    "t0 = time.time()\n",
    "conn = mysql.connector.connect(**DB_CONFIG, connection_timeout=5)\n",
    "print(\"connected in\", round(time.time()-t0, 2), \"seconds\")\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79df9f4-baf7-4ca5-8fc3-8e8ccfff4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(query, params=None, fetch=False):\n",
    "    \"\"\"\n",
    "    Execute a single SQL statement in MySQL.\n",
    "    - If fetch=True, returns fetched results (list of tuples).\n",
    "    - Otherwise commits the change and returns None.\n",
    "    NOTE: This helper executes ONE statement at a time.\n",
    "    \"\"\"\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(query, params or ())\n",
    "        if fetch:\n",
    "            return cursor.fetchall()\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695018b-dd8a-48fd-9cad-2f3190e330e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the table if it exists\n",
    "execute_sql(\"DROP TABLE IF EXISTS daily_weather;\")\n",
    "\n",
    "# Creating the daily_weather table to extract the weather variables\n",
    "execute_sql(\"\"\"\n",
    "CREATE TABLE daily_weather (\n",
    "    country_name VARCHAR(100) NOT NULL,\n",
    "    date DATE NOT NULL,\n",
    "\n",
    "    temperature_2m_mean DOUBLE,\n",
    "    temperature_2m_max DOUBLE,\n",
    "    temperature_2m_min DOUBLE,\n",
    "    precipitation_sum DOUBLE,\n",
    "    rain_sum DOUBLE,\n",
    "    et0_fao_evapotranspiration DOUBLE,\n",
    "\n",
    "    source VARCHAR(50) NOT NULL DEFAULT 'open-meteo-archive',\n",
    "    ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n",
    "\n",
    "    PRIMARY KEY (country_name, date)\n",
    ");\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4903bcf-63d3-43a6-b153-5a96ec8e5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part J: Logging all extraction activities including successes, failures and record counts\n",
    "for iso3_code, v in COUNTRY_CENTROIDS.items():\n",
    "    country_name = v[\"name\"]\n",
    "    lat, lon = v[\"lat\"], v[\"lon\"]\n",
    "\n",
    "    for year in range(2015, 2024):\n",
    "        start_date = f\"{year}-01-01\"\n",
    "        end_date = f\"{year}-12-31\"\n",
    "\n",
    "        logger.info(f\"{country_name}: Extraction started for {start_date} to {end_date}\")\n",
    "\n",
    "        json_data = fetch_weather_data(iso3_code, lat, lon, start_date, end_date)\n",
    "\n",
    "        if json_data is None:\n",
    "            logger.error(f\"{country_name}: Extraction failed (no JSON returned) | {year}\")\n",
    "            continue\n",
    "\n",
    "        rows = transform_weather_data(json_data, country_name)\n",
    "        record_count = len(rows)\n",
    "\n",
    "        if record_count == 0:\n",
    "            logger.error(f\"{country_name}: Extraction failed (0 records) | {year}\")\n",
    "            continue\n",
    "\n",
    "        upsert_daily_weather(rows, logger=logger)\n",
    "        logger.info(f\"{country_name}: Loaded {record_count} records to database\")\n",
    "        logger.info(f\"{country_name}: Extraction successful | year={year} | records_extracted={record_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c93326-0d15-4721-80c9-27033a85f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see the data saved in the table\n",
    "progress = execute_sql(\"\"\"\n",
    "SELECT country_name, COUNT(*) as rows_saved\n",
    "FROM daily_weather\n",
    "GROUP BY country_name\n",
    "\"\"\", fetch=True)\n",
    "\n",
    "progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241cdb5-fa0d-494b-a078-f33d9027cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the pipeline idempotent\n",
    "\n",
    "class DataStore:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        self.insert_count = 0\n",
    "        self.skip_count = 0\n",
    "\n",
    "    def upsert(self, key, record):\n",
    "        if key in self.data:\n",
    "            self.data[key] = record\n",
    "            self.skip_count += 1\n",
    "            return 'updated'\n",
    "        else:\n",
    "            self.data[key] = record\n",
    "            self.insert_count += 1\n",
    "            return 'inserted'\n",
    "\n",
    "    def get_stats(self):\n",
    "        return {\n",
    "            'total_records': len(self.data),\n",
    "            'inserted': self.insert_count,\n",
    "            'updated': self.skip_count\n",
    "        }\n",
    "\n",
    "# Now it exists\n",
    "store = DataStore()\n",
    "print(\"DataStore initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c736b-d74a-4368-8359-54493523f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proving idempotency\n",
    "store = DataStore()\n",
    "\n",
    "def run_once(country_name, lat, lon, year):\n",
    "    start_date = f\"{year}-01-01\"\n",
    "    end_date   = f\"{year}-12-31\"\n",
    "\n",
    "    json_data = fetch_weather_data(country_name, lat, lon, start_date, end_date)\n",
    "    if json_data is None:\n",
    "        return 0\n",
    "\n",
    "    rows = transform_weather_data(json_data, country_name)  # returns list of daily dicts\n",
    "    for r in rows:\n",
    "        key = (r[\"country_name\"], r[\"date\"])   # idempotent key\n",
    "        store.upsert(key, r)\n",
    "\n",
    "    return len(rows)\n",
    "\n",
    "# picking one country from the COUNTRY_CENTROIDS dict\n",
    "v = COUNTRY_CENTROIDS[\"CAN\"]  \n",
    "country_name, lat, lon = v[\"name\"], v[\"lat\"], v[\"lon\"]\n",
    "\n",
    "# Run 1\n",
    "n1 = run_once(country_name, lat, lon, 2019)\n",
    "stats1 = store.get_stats()\n",
    "print(\"Run 1 extracted:\", n1, \"| stats:\", stats1)\n",
    "\n",
    "# Run 2 (same exact request again)\n",
    "n2 = run_once(country_name, lat, lon, 2019)\n",
    "stats2 = store.get_stats()\n",
    "print(\"Run 2 extracted:\", n2, \"| stats:\", stats2)\n",
    "\n",
    "# Sanity checks\n",
    "assert stats2[\"total_records\"] == stats1[\"total_records\"], \"NOT idempotent: total_records increased\"\n",
    "assert stats2[\"inserted\"] == stats1[\"inserted\"], \"NOT idempotent: inserted increased on rerun\"\n",
    "assert stats2[\"updated\"] >= stats1[\"updated\"], \"Expected updates on rerun\"\n",
    "print(\"✅ DataStore idempotency test PASSED on real data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1166165-2a89-4783-8baa-bf81972703df",
   "metadata": {},
   "source": [
    "# Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed45c1-0073-4290-9912-7dc9aaf0be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running ETL twice and comparing rows\n",
    "rows_before = execute_sql(\"SELECT COUNT(*) FROM daily_weather\", fetch=True)[0][0]\n",
    " \n",
    "rows_after  = execute_sql(\"SELECT COUNT(*) FROM daily_weather\", fetch=True)[0][0]\n",
    "\n",
    "print(\"Before:\", rows_before)\n",
    "print(\"After:\", rows_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386290b-ca19-4010-ad79-2edf89ca6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying if there are zero duplicates\n",
    "duplicates = execute_sql(\"\"\"\n",
    "SELECT country_name, date, COUNT(*) AS n\n",
    "FROM daily_weather\n",
    "GROUP BY country_name, date\n",
    "HAVING n > 1\n",
    "\"\"\", fetch=True)\n",
    "\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96c839-e105-4818-a25e-244c9e42be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part L: Creating aggregated view of monthly weather summaries by country\n",
    "\n",
    "execute_sql(\"DROP VIEW IF EXISTS monthly_weather;\")\n",
    "\n",
    "execute_sql(\"\"\"\n",
    "CREATE VIEW monthly_weather AS\n",
    "SELECT\n",
    "    country_name,\n",
    "    YEAR(date)  AS year,\n",
    "    MONTH(date) AS month,\n",
    "\n",
    "    -- Basic monthly summaries\n",
    "    AVG(temperature_2m_mean) AS avg_temp_mean_c,\n",
    "    AVG(temperature_2m_max)  AS avg_temp_max_c,\n",
    "    AVG(temperature_2m_min)  AS avg_temp_min_c,\n",
    "\n",
    "    SUM(precipitation_sum) AS total_precip_mm,\n",
    "    SUM(rain_sum)          AS total_rain_mm,\n",
    "    SUM(et0_fao_evapotranspiration) AS total_et0_mm,\n",
    "\n",
    "    COUNT(*) AS n_days,\n",
    "\n",
    "    -- Derived: Growing Degree Days (base 10C)\n",
    "    SUM(CASE\n",
    "        WHEN temperature_2m_mean IS NULL THEN 0\n",
    "        WHEN temperature_2m_mean > 10 THEN (temperature_2m_mean - 10)\n",
    "        ELSE 0\n",
    "    END) AS gdd_base10,\n",
    "\n",
    "    -- Derived: Extreme temperature days\n",
    "    SUM(CASE WHEN temperature_2m_max > 35 THEN 1 ELSE 0 END) AS extreme_hot_days_gt35c,\n",
    "    SUM(CASE WHEN temperature_2m_min < 0  THEN 1 ELSE 0 END) AS freeze_days_lt0c,\n",
    "\n",
    "    -- Derived: Precipitation variability (CV^2)\n",
    "    CASE\n",
    "        WHEN AVG(precipitation_sum) IS NULL OR AVG(precipitation_sum) = 0 THEN NULL\n",
    "        ELSE (AVG(precipitation_sum * precipitation_sum) - POW(AVG(precipitation_sum), 2))\n",
    "             / POW(AVG(precipitation_sum), 2)\n",
    "    END AS precip_variability_cv2\n",
    "\n",
    "FROM daily_weather\n",
    "GROUP BY country_name, YEAR(date), MONTH(date);\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8063a33-613f-4f63-ae90-9f73c1d39aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part M: Creating an aggregated view of yearly variables\n",
    "\n",
    "execute_sql(\"DROP VIEW IF EXISTS annual_weather;\")\n",
    "\n",
    "execute_sql(\"\"\"\n",
    "CREATE VIEW annual_weather AS\n",
    "SELECT\n",
    "    country_name,\n",
    "    YEAR(date) AS year,\n",
    "\n",
    "    -- Basic annual summaries\n",
    "    AVG(temperature_2m_mean) AS avg_temp_mean_c,\n",
    "    AVG(temperature_2m_max)  AS avg_temp_max_c,\n",
    "    AVG(temperature_2m_min)  AS avg_temp_min_c,\n",
    "\n",
    "    SUM(precipitation_sum) AS total_precip_mm,\n",
    "    SUM(rain_sum)          AS total_rain_mm,\n",
    "    SUM(et0_fao_evapotranspiration) AS total_et0_mm,\n",
    "\n",
    "    COUNT(*) AS n_days,\n",
    "\n",
    "    -- Derived: Growing Degree Days (base 10C)\n",
    "    SUM(CASE\n",
    "        WHEN temperature_2m_mean IS NULL THEN 0\n",
    "        WHEN temperature_2m_mean > 10 THEN (temperature_2m_mean - 10)\n",
    "        ELSE 0\n",
    "    END) AS gdd_base10,\n",
    "\n",
    "    -- Derived: Extreme temperature days\n",
    "    SUM(CASE WHEN temperature_2m_max > 35 THEN 1 ELSE 0 END) AS extreme_hot_days_gt35c,\n",
    "    SUM(CASE WHEN temperature_2m_min < 0  THEN 1 ELSE 0 END) AS freeze_days_lt0c,\n",
    "\n",
    "    -- Derived: Precipitation variability (CV^2)\n",
    "    CASE\n",
    "        WHEN AVG(precipitation_sum) IS NULL OR AVG(precipitation_sum) = 0 THEN NULL\n",
    "        ELSE (AVG(precipitation_sum * precipitation_sum) - POW(AVG(precipitation_sum), 2))\n",
    "             / POW(AVG(precipitation_sum), 2)\n",
    "    END AS precip_variability_cv2\n",
    "\n",
    "FROM daily_weather\n",
    "GROUP BY country_name, YEAR(date);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0b07f-4a19-42a9-a41c-2ec47136c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part N: Creating an integrated view that combines weather data with crop production data (MySQL)\n",
    "\n",
    "execute_sql(\"DROP VIEW IF EXISTS country_year_weather_crop;\")\n",
    "\n",
    "execute_sql(\"\"\"\n",
    "CREATE VIEW country_year_weather_crop AS\n",
    "SELECT\n",
    "    c.country_id,\n",
    "    c.country_name,\n",
    "    c.iso3_code,\n",
    "    c.region,\n",
    "    c.income_group,\n",
    "\n",
    "    cp.year,\n",
    "    cp.crop,\n",
    "    cp.yield_kg_ha,\n",
    "    cp.production_tonnes,\n",
    "    cp.area_harvested_ha,\n",
    "    cp.fertilizer_use_kg_ha,\n",
    "    cp.irrigation_pct,\n",
    "\n",
    "    aw.avg_temp_mean_c,\n",
    "    aw.avg_temp_max_c,\n",
    "    aw.avg_temp_min_c,\n",
    "    aw.total_precip_mm,\n",
    "    aw.total_rain_mm,\n",
    "    aw.total_et0_mm,\n",
    "    aw.gdd_base10,\n",
    "    aw.extreme_hot_days_gt35c,\n",
    "    aw.freeze_days_lt0c,\n",
    "    aw.precip_variability_cv2\n",
    "\n",
    "FROM crop_production cp\n",
    "JOIN countries c\n",
    "    ON c.country_id = cp.country_id\n",
    "JOIN annual_weather aw\n",
    "    ON aw.country_name = c.country_name\n",
    "   AND aw.year = cp.year;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c85fc-baa9-4ca7-970a-14acbacf0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the integrated view (top 10 rows)\n",
    "read_table(\"\"\"\n",
    "SELECT *\n",
    "FROM country_year_weather_crop\n",
    "LIMIT 10;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae0000-7091-4b0f-b922-3e42e06c0597",
   "metadata": {},
   "source": [
    "# Question 1: Indentifying Climate Vulnerable Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa3c22-1fff-4898-843e-651177c27d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for the major cereals\n",
    "selected_crops = \"\"\"\n",
    "SELECT *\n",
    "FROM country_year_weather_crop\n",
    "WHERE crop IN ('Wheat','Rice','Maize','Soybeans');\n",
    "\"\"\"\n",
    "\n",
    "df_cereals = read_table(selected_crops)\n",
    "\n",
    "df_cereals = df_cereals.dropna(subset=[\n",
    "    \"yield_kg_ha\",\n",
    "    \"avg_temp_mean_c\",\n",
    "    \"precip_variability_cv2\",\n",
    "    \"fertilizer_use_kg_ha\",\n",
    "    \"irrigation_pct\"\n",
    "])\n",
    "\n",
    "df_cereals[\"year\"] = df_cereals[\"year\"].astype(int)\n",
    "df_cereals.head()\n",
    "\n",
    "df_cereals.to_csv(\"final_analysis_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebe949-b4e7-4e46-ad75-1d3f4cf343d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using country and year fixed effects to know how much yield falls when temperature rises\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "results = []\n",
    "\n",
    "for crop in [\"Wheat\", \"Rice\", \"Maize\", \"Soybeans\"]:\n",
    "    df = df_cereals[df_cereals[\"crop\"] == crop].copy()\n",
    "\n",
    "    # OLS with controls + country FE + year FE\n",
    "    model = smf.ols(\n",
    "        \"yield_kg_ha ~ avg_temp_mean_c + precip_variability_cv2 + total_precip_mm \"\n",
    "        \"+ fertilizer_use_kg_ha + irrigation_pct + C(country_name) + C(year)\",\n",
    "        data=df\n",
    "    ).fit(cov_type=\"HC1\")\n",
    "\n",
    "    results.append({\n",
    "        \"crop\": crop,\n",
    "        \"n\": int(model.nobs),\n",
    "        \"beta_temp\": model.params.get(\"avg_temp_mean_c\"),\n",
    "        \"p_temp\": model.pvalues.get(\"avg_temp_mean_c\"),\n",
    "        \"beta_precip_var\": model.params.get(\"precip_variability_cv2\"),\n",
    "        \"p_precip_var\": model.pvalues.get(\"precip_variability_cv2\"),\n",
    "    })\n",
    "\n",
    "res = pd.DataFrame(results)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa9b57-1e1a-4f8a-bfb3-eb57b93981f1",
   "metadata": {},
   "source": [
    "Country and year fixed effects are included to isolate the impact of climate variability on crop yields from confounding factors. Country fixed effects control for time-invariant characteristics such as soil quality, geography, agricultural institutions, and baseline technology, ensuring that identification comes from changes in climate conditions within a country over time rather than differences across countries. Year fixed effects account for global shocks and trends that affect all countries simultaneously, including technological progress, input price fluctuations, and worldwide climate phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389a4ea-9b7e-4f6f-a1b1-93e7c32b73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the ranked vulnerability assessment\n",
    "\n",
    "# Strongest negative response to temperature increases\n",
    "temp_rank = res.sort_values(\"beta_temp\", ascending=True)[[\"crop\",\"n\",\"beta_temp\",\"p_temp\"]]\n",
    "\n",
    "# Most sensitive to precipitation variability\n",
    "precip_rank = res.sort_values(\"beta_precip_var\", ascending=True)[[\"crop\",\"n\",\"beta_precip_var\",\"p_precip_var\"]]\n",
    "\n",
    "temp_rank, precip_rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc75119-7189-419e-b063-3821cc98a228",
   "metadata": {},
   "source": [
    "Using country- and year-fixed effects regressions that control for fertilizer intensity and irrigation, we find substantial heterogeneity in crop yield responses to climate conditions. Among the four major cereals examined, soybeans exhibit the strongest negative response to temperature increases, with estimated yields declining by approximately 78 kg/ha for a one-unit increase in average temperature. Rice also shows a negative temperature response (−57 kg/ha), though the magnitude is smaller than for soybeans. In contrast, wheat and maize do not display strong negative temperature sensitivity in this specification, suggesting greater tolerance to gradual warming. With respect to precipitation variability, maize is the most climate-vulnerable crop, experiencing yield reductions of roughly 5.7 kg/ha as rainfall becomes more volatile, followed closely by wheat. Rice and soybeans appear comparatively resilient to precipitation variability, consistent with the prevalence of irrigation and adaptive water management in their production systems. While coefficient estimates are not statistically precise, the relative magnitudes provide a clear ranking of climate vulnerability across crops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c45de-031b-4e3c-837f-7488cbef9b16",
   "metadata": {},
   "source": [
    "## Extension: Do vulnerabilities differ by income groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fecdf0f-dd45-45a2-88e0-27fd2f8c6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_results = []\n",
    "\n",
    "income_groups = sorted(df_cereals[\"income_group\"].dropna().unique())\n",
    "\n",
    "for income in income_groups:\n",
    "    for crop in [\"Wheat\", \"Rice\", \"Maize\", \"Soybeans\"]:\n",
    "        df = df_cereals[(df_cereals[\"income_group\"] == income) & (df_cereals[\"crop\"] == crop)].copy()\n",
    "\n",
    "        # Skip tiny samples (prevents unstable results / errors)\n",
    "        if df.shape[0] < 30:\n",
    "            continue\n",
    "\n",
    "        model = smf.ols(\n",
    "            \"yield_kg_ha ~ avg_temp_mean_c + precip_variability_cv2 + total_precip_mm \"\n",
    "            \"+ fertilizer_use_kg_ha + irrigation_pct + C(country_name) + C(year)\",\n",
    "            data=df\n",
    "        ).fit(cov_type=\"HC1\")\n",
    "\n",
    "        ext_results.append({\n",
    "            \"income_group\": income,\n",
    "            \"crop\": crop,\n",
    "            \"n\": int(model.nobs),\n",
    "            \"beta_temp\": model.params.get(\"avg_temp_mean_c\"),\n",
    "            \"p_temp\": model.pvalues.get(\"avg_temp_mean_c\"),\n",
    "            \"beta_precip_var\": model.params.get(\"precip_variability_cv2\"),\n",
    "            \"p_precip_var\": model.pvalues.get(\"precip_variability_cv2\"),\n",
    "        })\n",
    "\n",
    "ext_res = pd.DataFrame(ext_results)\n",
    "ext_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4f72e-e987-48f7-9bf5-9fda7c882265",
   "metadata": {},
   "source": [
    "Climate vulnerability varies substantially across income groups, underscoring the role of adaptive capacity in mediating climate impacts. In high-income countries, maize yields exhibit a positive and statistically significant response to temperature increases, suggesting that technological inputs, irrigation, and management practices can offset or even reverse warming effects. In contrast, maize displays large and negative temperature responses in lower-middle-income and upper-middle-income countries, indicating heightened vulnerability in these settings. Precipitation variability further exacerbates yield losses for maize across income categories, with particularly strong negative effects in upper-middle-income countries. Rice shows comparatively greater resilience to rainfall variability but remains sensitive to temperature increases in low-income countries. Overall, these results suggest that income-related differences in adaptation capacity play a critical role in shaping crop-level climate vulnerability, and that maize-focused adaptation strategies are especially urgent in lower- and upper-middle-income countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1f65b-9759-45b8-930e-3e883706aeb7",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622588a3-06aa-4c38-86e2-31fab080880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load integrated dataset from MySQL view\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pull the integrated view created earlier (country + crop + yearly weather + inputs)\n",
    "df = read_table(\"SELECT * FROM country_year_weather_crop;\")\n",
    "\n",
    "# Basic cleaning\n",
    "df = df.copy()\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "\n",
    "# Keep only rows where key outcomes exist\n",
    "df = df.dropna(subset=[\n",
    "    \"country_name\", \"crop\", \"year\",\n",
    "    \"yield_kg_ha\",\n",
    "    \"avg_temp_mean_c\",\n",
    "    \"total_precip_mm\"\n",
    "])\n",
    "\n",
    "\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e45a2c-471a-4efb-b14d-4fc74145b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates at the key level\n",
    "dup = df.duplicated(subset=[\"country_name\", \"year\", \"crop\"]).sum()\n",
    "print(\"Duplicate country-year-crop rows:\", dup)\n",
    "\n",
    "# If duplicates exist, keep one row (or average)\n",
    "df = df.groupby([\"country_name\", \"year\", \"crop\"], as_index=False).mean(numeric_only=True)\\\n",
    "       .merge(df[[\"country_name\",\"year\",\"crop\",\"iso3_code\",\"region\",\"income_group\"]].drop_duplicates(),\n",
    "              on=[\"country_name\",\"year\",\"crop\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbbe3f-cab3-4a31-953c-87bed34a7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-level climate variability (across years)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_cv(x):\n",
    "    x = pd.Series(x).dropna()\n",
    "    if len(x) < 3:\n",
    "        return np.nan\n",
    "    m = x.mean()\n",
    "    if m == 0:\n",
    "        return np.nan\n",
    "    return x.std(ddof=1) / m\n",
    "\n",
    "country_climate = (\n",
    "    df.groupby(\"country_name\")\n",
    "      .agg(\n",
    "          temp_sd=(\"avg_temp_mean_c\", lambda s: s.std(ddof=1)),\n",
    "          temp_cv=(\"avg_temp_mean_c\", safe_cv),\n",
    "          precip_sd=(\"total_precip_mm\", lambda s: s.std(ddof=1)),\n",
    "          precip_cv=(\"total_precip_mm\", safe_cv),\n",
    "          hot_days_mean=(\"extreme_hot_days_gt35c\", \"mean\"),\n",
    "          freeze_days_mean=(\"freeze_days_lt0c\", \"mean\"),\n",
    "          precip_intra_cv=(\"precip_variability_cv2\", \"mean\"),\n",
    "          n_years=(\"year\", \"nunique\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "#  Use a smaller threshold so we don't drop all countries\n",
    "country_climate = country_climate[country_climate[\"n_years\"] >= 5].copy()\n",
    "\n",
    "# Quick checks\n",
    "country_climate.shape, country_climate[\"n_years\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1b4a8-9d08-4922-9ebd-66b94633d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yield stability (country–crop yield variability)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_cv(x):\n",
    "    x = pd.Series(x).dropna()\n",
    "    if len(x) < 3:\n",
    "        return np.nan\n",
    "    m = x.mean()\n",
    "    if m == 0:\n",
    "        return np.nan\n",
    "    return x.std(ddof=1) / m\n",
    "\n",
    "yield_stability = (\n",
    "    df.groupby([\"country_name\", \"crop\"])\n",
    "      .agg(\n",
    "          yield_mean=(\"yield_kg_ha\", \"mean\"),\n",
    "          yield_sd=(\"yield_kg_ha\", lambda s: s.std(ddof=1)),\n",
    "          yield_cv=(\"yield_kg_ha\", safe_cv),\n",
    "          n_years=(\"year\", \"nunique\"),\n",
    "          region=(\"region\", lambda s: s.dropna().mode().iloc[0] if len(s.dropna()) else np.nan),\n",
    "          income_group=(\"income_group\", lambda s: s.dropna().mode().iloc[0] if len(s.dropna()) else np.nan),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Keep only country–crop pairs with enough years\n",
    "yield_stability = yield_stability[yield_stability[\"n_years\"] >= 5].copy()\n",
    "\n",
    "yield_stability.sort_values(\"yield_cv\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f535695-f32d-4b8e-b2a6-8a5e4d843431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge climate exposure with yield stability\n",
    "\n",
    "\n",
    "q3 = (\n",
    "    yield_stability\n",
    "      .merge(country_climate, on=\"country_name\", how=\"inner\")\n",
    ")\n",
    "\n",
    "q3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6cba14-e6e0-4293-b751-92e6d6186a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resilience (median-based classification)\n",
    "\n",
    "\n",
    "# Climate exposure measure\n",
    "q3[\"climate_exposure\"] = (\n",
    "    (q3[\"temp_sd\"] - q3[\"temp_sd\"].mean()) / q3[\"temp_sd\"].std(ddof=1) +\n",
    "    (q3[\"precip_cv\"] - q3[\"precip_cv\"].mean()) / q3[\"precip_cv\"].std(ddof=1)\n",
    ")\n",
    "\n",
    "# Cutoffs\n",
    "climate_cut = q3[\"climate_exposure\"].median()\n",
    "yield_cut   = q3[\"yield_cv\"].median()\n",
    "\n",
    "# Classification\n",
    "q3[\"resilience_class\"] = \"Other\"\n",
    "\n",
    "q3.loc[\n",
    "    (q3[\"climate_exposure\"] >= climate_cut) &\n",
    "    (q3[\"yield_cv\"] <= yield_cut),\n",
    "    \"resilience_class\"\n",
    "] = \"RESILIENT\"\n",
    "\n",
    "q3.loc[\n",
    "    (q3[\"climate_exposure\"] >= climate_cut) &\n",
    "    (q3[\"yield_cv\"] > yield_cut),\n",
    "    \"resilience_class\"\n",
    "] = \"VULNERABLE\"\n",
    "\n",
    "q3[\"resilience_class\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8dfcc-03f7-4fbc-9012-cb6e8ff1264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize resilience vs vulnerability\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for label, dsub in q3.groupby(\"resilience_class\"):\n",
    "    plt.scatter(\n",
    "        dsub[\"climate_exposure\"],\n",
    "        dsub[\"yield_cv\"],\n",
    "        alpha=0.65,\n",
    "        label=label\n",
    "    )\n",
    "\n",
    "plt.axvline(climate_cut, linestyle=\"--\", linewidth=1)\n",
    "plt.axhline(yield_cut, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Climate Exposure Index (higher = more variable climate)\")\n",
    "plt.ylabel(\"Yield Variability (CV of yield)\")\n",
    "plt.title(\"Q3: Resilient vs Vulnerable Agricultural Systems\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"resilient_vs_vulnerable.png\", dpi=250, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24f051-799a-449c-9bf7-c84be3358b43",
   "metadata": {},
   "source": [
    "This figure plots yield stability against climate exposure. Systems in the bottom-right quadrant are classified as resilient because they maintain stable yields despite experiencing high climate variability. In contrast, systems in the top-right quadrant face similar climate stress but show high yield volatility, indicating vulnerability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410897e9-0e92-4cdb-9935-0286abb76d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare drivers of resilience\n",
    "\n",
    "\n",
    "drivers_summary = (\n",
    "    q3[q3[\"resilience_class\"].isin([\"RESILIENT\", \"VULNERABLE\"])]\n",
    "      .groupby(\"resilience_class\")\n",
    "      .agg(\n",
    "          hot_days_mean=(\"hot_days_mean\", \"mean\"),\n",
    "          freeze_days_mean=(\"freeze_days_mean\", \"mean\"),\n",
    "          precip_intra_cv=(\"precip_intra_cv\", \"mean\"),\n",
    "          avg_yield_cv=(\"yield_cv\", \"mean\")\n",
    "      )\n",
    ")\n",
    "\n",
    "drivers_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7e1d2-6d74-42f7-9bee-3cff859cff39",
   "metadata": {},
   "source": [
    "Resilient and vulnerable systems experience similar levels of heat exposure and precipitation variability. However, vulnerable systems face substantially higher exposure to freezing temperatures, which is associated with significantly greater yield volatility. This suggests that resilience is driven less by reduced climate exposure and more by the ability to manage specific climate stresses, particularly cold extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb625e-9bad-4f86-8648-358b5b4533f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case studies (top examples)\n",
    "\n",
    "\n",
    "resilient_cases = (\n",
    "    q3[q3[\"resilience_class\"]==\"RESILIENT\"]\n",
    "      .sort_values([\"climate_exposure\",\"yield_cv\"], ascending=[False, True])\n",
    "      [[\"country_name\",\"crop\",\"region\",\"income_group\",\n",
    "        \"climate_exposure\",\"yield_cv\",\n",
    "        \"hot_days_mean\",\"freeze_days_mean\",\"precip_intra_cv\"]]\n",
    "      .head(5)\n",
    ")\n",
    "\n",
    "vulnerable_cases = (\n",
    "    q3[q3[\"resilience_class\"]==\"VULNERABLE\"]\n",
    "      .sort_values([\"climate_exposure\",\"yield_cv\"], ascending=[False, False])\n",
    "      [[\"country_name\",\"crop\",\"region\",\"income_group\",\n",
    "        \"climate_exposure\",\"yield_cv\",\n",
    "        \"hot_days_mean\",\"freeze_days_mean\",\"precip_intra_cv\"]]\n",
    "      .head(5)\n",
    ")\n",
    "\n",
    "resilient_cases, vulnerable_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccebfb-9eac-4520-b0eb-a815fd22d619",
   "metadata": {},
   "source": [
    "This table presents representative case studies of resilient and vulnerable agricultural systems identified in the analysis. The selected systems experience high levels of climate exposure, as reflected by elevated values of the climate exposure index, but differ markedly in their yield stability.\n",
    "\n",
    "Resilient systems, such as rice and wheat production in Morocco and wheat production in Australia, maintain relatively low yield variability despite substantial climate stress. These systems face frequent extreme heat events and, in some cases, notable precipitation variability, yet their yields remain stable. This suggests the presence of effective adaptation mechanisms, including appropriate crop selection, management practices, and technological capacity.\n",
    "\n",
    "In contrast, vulnerable systems—such as maize and soybean production in Morocco and maize and wheat production in Egypt—exhibit significantly higher yield variability under similar levels of climate exposure. These systems are more sensitive to climate extremes, indicating limited adaptive capacity or greater crop-specific vulnerability.\n",
    "\n",
    "Overall, the comparison highlights that resilience is not driven by reduced exposure to climate variability, but rather by the ability of agricultural systems to manage climate stress and stabilize production outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f57a4f4-09f8-4b3c-9f35-470571feaf09",
   "metadata": {},
   "source": [
    "# Question 4: Production Trends and Future Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d55e59-c195-44c3-b0e7-bcaf7e69a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for Q4\n",
    "df_4=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf03d0-efb1-495b-bb16-271ea9e064ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select baseline period and create subset based on those years\n",
    "\n",
    "BASE_START, BASE_END = 2015, 2023\n",
    "\n",
    "baseline = df_4[(df_4[\"year\"] >= BASE_START) & (df_4[\"year\"] <= BASE_END)].copy()\n",
    "\n",
    "use_fallback = baseline.empty\n",
    "\n",
    "# Define grouping levels\n",
    "group_keys = [\"country_id\", \"crop\"]\n",
    "\n",
    "# Take mean of yearly to establish baseline for each country_crop combination\n",
    "if not use_fallback:\n",
    "    base_stats = baseline.groupby(group_keys).agg(\n",
    "        base_temp=(\"avg_temp_mean_c\",\"mean\"),\n",
    "        base_precip=(\"total_precip_mm\",\"mean\"),\n",
    "        base_gdd=(\"gdd_base10\",\"mean\"),\n",
    "        base_hot=(\"extreme_hot_days_gt35c\",\"mean\"),\n",
    "        base_freeze=(\"freeze_days_lt0c\",\"mean\"),\n",
    "    ).reset_index()\n",
    "else:\n",
    "    base_stats = df_4.groupby(group_keys).agg(\n",
    "        base_temp=(\"avg_temp_mean_c\",\"mean\"),\n",
    "        base_precip=(\"total_precip_mm\",\"mean\"),\n",
    "        base_gdd=(\"gdd_base10\",\"mean\"),\n",
    "        base_hot=(\"extreme_hot_days_gt35c\",\"mean\"),\n",
    "        base_freeze=(\"freeze_days_lt0c\",\"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "# Merge new baseline values into original dataframe\n",
    "df_4 = df_4.merge(base_stats, on=group_keys, how=\"left\")\n",
    "\n",
    "# Create anomoly columns by subtracting baseline values from observed values\n",
    "df_4[\"temp_anom\"]   = df_4[\"avg_temp_mean_c\"] - df_4[\"base_temp\"]\n",
    "df_4[\"precip_anom\"] = df_4[\"total_precip_mm\"] - df_4[\"base_precip\"]\n",
    "df_4[\"gdd_anom\"]    = df_4[\"gdd_base10\"] - df_4[\"base_gdd\"]\n",
    "df_4[\"hot_anom\"]    = df_4[\"extreme_hot_days_gt35c\"] - df_4[\"base_hot\"]\n",
    "df_4[\"freeze_anom\"] = df_4[\"freeze_days_lt0c\"] - df_4[\"base_freeze\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a126ec1-39b7-4754-9711-8f49d3eccab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create log yield and associated regression\n",
    "df_4[\"ln_yield\"] = np.log(df_4[\"yield_kg_ha\"])\n",
    "\n",
    "def run_crop_model(data):\n",
    "    d = data.dropna(subset=[\n",
    "        \"ln_yield\",\n",
    "        \"temp_anom\",\n",
    "        \"precip_anom\",\n",
    "        \"irrigation_pct\"\n",
    "    ])\n",
    "    \n",
    "    if d[\"country_id\"].nunique() < 10:\n",
    "        return None\n",
    "    \n",
    "    formula = \"\"\"\n",
    "    ln_yield ~ temp_anom\n",
    "             + precip_anom\n",
    "             + irrigation_pct\n",
    "             + temp_anom:irrigation_pct\n",
    "             + C(country_id)\n",
    "             + C(year)\n",
    "    \"\"\"\n",
    "    \n",
    "    model_4 = smf.ols(\n",
    "        formula,\n",
    "        data=d\n",
    "    ).fit(\n",
    "        cov_type=\"cluster\",\n",
    "        cov_kwds={\"groups\": d[\"country_id\"]}\n",
    "    )\n",
    "    \n",
    "    return model_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68830dda-4a00-483a-9191-d6b75379390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_models = {}\n",
    "\n",
    "for crop, g in df_4.groupby(\"crop\"):\n",
    "    m = run_crop_model(g)\n",
    "    if m is not None:\n",
    "        crop_models[crop] = m\n",
    "\n",
    "len(crop_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3de1d-efc6-42a2-98c6-bda016094a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for crop, m in crop_models.items():\n",
    "    rows.append({\n",
    "        \"crop\": crop,\n",
    "        \"beta_temp\": m.params[\"temp_anom\"],\n",
    "        \"beta_precip\": m.params[\"precip_anom\"],\n",
    "        \"beta_irrig\": m.params[\"irrigation_pct\"],\n",
    "        \"beta_temp_x_irrig\": m.params[\"temp_anom:irrigation_pct\"],\n",
    "        \"n_obs\": int(m.nobs)\n",
    "    })\n",
    "\n",
    "climate_results = pd.DataFrame(rows)\n",
    "climate_results.sort_values(\"beta_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b159af8-c64f-47b8-a56b-9dc9a0a13bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECENT_START, RECENT_END = 2015, 2023\n",
    "\n",
    "recent = df_4[(df_4[\"year\"] >= RECENT_START) & \n",
    "              (df_4[\"year\"] <= RECENT_END)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f0a6e-a6cd-4c54-bb9e-426faa136a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to estimate slope\n",
    "def trend_slope(group, ycol):\n",
    "    g = group.dropna(subset=[ycol, \"year\"])\n",
    "    if len(g) < 8:\n",
    "        return np.nan\n",
    "    m = smf.ols(f\"{ycol} ~ year\", data=g).fit()\n",
    "    return m.params[\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c4e9f-5b5a-4b2b-847e-9da206dc7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute slope for each country_crop\n",
    "rows = []\n",
    "\n",
    "for (cid, crop), g in recent.groupby([\"country_id\",\"crop\"]):\n",
    "    slope = trend_slope(g, \"ln_yield\")\n",
    "    rows.append({\n",
    "        \"country_id\": cid,\n",
    "        \"country_name\": g[\"country_name\"].iloc[0],\n",
    "        \"iso3_code\": g[\"iso3_code\"].iloc[0],\n",
    "        \"region\": g[\"region\"].iloc[0],\n",
    "        \"income_group\": g[\"income_group\"].iloc[0],\n",
    "        \"crop\": crop,\n",
    "        \"yield_growth_rate\": slope\n",
    "    })\n",
    "\n",
    "yield_trends = pd.DataFrame(rows)\n",
    "yield_trends[\"yield_pct_per_year\"] = 100 * yield_trends[\"yield_growth_rate\"]\n",
    "yield_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a7ef4-ba13-46b7-95fc-e30d7ccc7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criteria for stagnation and decline\n",
    "STAGNATION = 2\n",
    "DECLINE    = 0.0\n",
    "\n",
    "yield_trends[\"yield_flag\"] = np.select(\n",
    "    [\n",
    "        yield_trends[\"yield_pct_per_year\"] < DECLINE,\n",
    "        yield_trends[\"yield_pct_per_year\"] < STAGNATION\n",
    "    ],\n",
    "    [\"declining\",\"stagnating\"],\n",
    "    default=\"growing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5941f-6639-457e-a759-204a5088d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View worst performers\n",
    "yield_trends.sort_values(\"yield_pct_per_year\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9955e-9b2d-478c-939c-14cd396884d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize results by region\n",
    "region_summary = (\n",
    "    yield_trends\n",
    "      .groupby([\"region\",\"crop\",\"yield_flag\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"n\")\n",
    ")\n",
    "\n",
    "display(region_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99a1d4-cdf0-47b4-98f9-3155fde66aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log values for area harvested and production\n",
    "df_4[\"ln_area\"] = np.log(df_4[\"area_harvested_ha\"])\n",
    "df_4[\"ln_prod\"] = np.log(df_4[\"production_tonnes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032a8b1-2cdc-4052-a4c3-bfc6f9855ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECENT_START, RECENT_END = 2015, 2023\n",
    "recent = df_4[(df_4[\"year\"] >= RECENT_START) & (df_4[\"year\"] <= RECENT_END)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711c1e7-0293-4070-b2cf-e94e7ef4ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_change(g, col):\n",
    "    g = g.sort_values(\"year\")\n",
    "    return g.iloc[-1][col] - g.iloc[0][col]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for (cid, crop), g in recent.groupby([\"country_id\",\"crop\"]):\n",
    "    g = g.dropna(subset=[\"ln_yield\",\"ln_area\",\"ln_prod\"])\n",
    "    if g[\"year\"].nunique() < 2:\n",
    "        continue\n",
    "    \n",
    "    dln_y = endpoint_change(g, \"ln_yield\")\n",
    "    dln_a = endpoint_change(g, \"ln_area\")\n",
    "    dln_p = endpoint_change(g, \"ln_prod\")\n",
    "    \n",
    "    rows.append({\n",
    "        \"country_id\": cid,\n",
    "        \"country_name\": g[\"country_name\"].iloc[0],\n",
    "        \"iso3_code\": g[\"iso3_code\"].iloc[0],\n",
    "        \"region\": g[\"region\"].iloc[0],\n",
    "        \"income_group\": g[\"income_group\"].iloc[0],\n",
    "        \"crop\": crop,\n",
    "        \"dln_yield\": 100 * dln_y,\n",
    "        \"dln_area\":  100 * dln_a,\n",
    "        \"dln_prod\":  100 * dln_p,\n",
    "        \"identity_gap\": 100 * (dln_p - (dln_y + dln_a)),\n",
    "    })\n",
    "\n",
    "decomp = pd.DataFrame(rows)\n",
    "decomp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22e6e1-dd8b-45d0-8c5a-f4c1bcebf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize by region\n",
    "region_decomp = (\n",
    "    decomp.groupby([\"region\",\"crop\"], as_index=False)\n",
    "          .agg(\n",
    "              avg_dln_yield=(\"dln_yield\",\"mean\"),\n",
    "              avg_dln_area=(\"dln_area\",\"mean\"),\n",
    "              avg_dln_prod=(\"dln_prod\",\"mean\"),\n",
    "              n=(\"country_id\",\"nunique\")\n",
    "          )\n",
    ")\n",
    "\n",
    "display(region_decomp.sort_values([\"crop\",\"avg_dln_prod\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c6534-1501-4338-bf53-532bac174e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify stagnating yields and growing harvest areas\n",
    "decomp_with_flags = decomp.merge(\n",
    "    yield_trends[[\"country_id\",\"crop\",\"yield_flag\",\"yield_pct_per_year\"]],\n",
    "    on=[\"country_id\",\"crop\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "area_driven = decomp_with_flags[\n",
    "    (decomp_with_flags[\"yield_flag\"].isin([\"stagnating\",\"declining\"])) &\n",
    "    (decomp_with_flags[\"dln_prod\"] > 0) &\n",
    "    (decomp_with_flags[\"dln_area\"] > 0)\n",
    "].sort_values(\"dln_area\", ascending=False)\n",
    "\n",
    "display(area_driven.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da9896-ba26-4bd9-8c59-a67eaf64cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recent production growth rates\n",
    "def prod_trend_slope(group):\n",
    "    g = group.dropna(subset=[\"ln_prod\",\"year\"])\n",
    "    if len(g) < 5:\n",
    "        return np.nan\n",
    "    m = smf.ols(\"ln_prod ~ year\", data=g).fit()\n",
    "    return m.params[\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa6896-b4b8-4975-ac60-94ee8e2a1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production growth by country_crop\n",
    "rows = []\n",
    "\n",
    "for (cid, crop), g in recent.groupby([\"country_id\",\"crop\"]):\n",
    "    slope = prod_trend_slope(g)\n",
    "    rows.append({\n",
    "        \"country_id\": cid,\n",
    "        \"country_name\": g[\"country_name\"].iloc[0],\n",
    "        \"iso3_code\": g[\"iso3_code\"].iloc[0],\n",
    "        \"region\": g[\"region\"].iloc[0],\n",
    "        \"income_group\": g[\"income_group\"].iloc[0],\n",
    "        \"crop\": crop,\n",
    "        \"prod_growth_rate\": slope\n",
    "    })\n",
    "\n",
    "prod_trends = pd.DataFrame(rows)\n",
    "prod_trends[\"prod_pct_per_year\"] = 100 * prod_trends[\"prod_growth_rate\"]\n",
    "prod_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b31bd-1613-4d26-9be1-7ae2ec92c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify future shortfall risk\n",
    "prod_trends[\"prod_flag\"] = np.select(\n",
    "    [\n",
    "        prod_trends[\"prod_pct_per_year\"] < 0,\n",
    "        prod_trends[\"prod_pct_per_year\"] < 2\n",
    "    ],\n",
    "    [\"declining\",\"stagnating\"],\n",
    "    default=\"growing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd3865-a620-42e0-82a0-b7ad03075032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify risks by region_crop\n",
    "\n",
    "region_risk = (\n",
    "    prod_trends\n",
    "      .groupby([\"region\",\"crop\",\"prod_flag\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"n\")\n",
    ")\n",
    "\n",
    "display(region_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc60895-2c1d-49be-b0b8-a0d0f0bba399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine yield production/yield/harvest analysis with climate sensitivity dataframe\n",
    "high_risk = prod_trends.merge(\n",
    "    yield_trends[[\"country_id\",\"crop\",\"yield_flag\"]],\n",
    "    on=[\"country_id\",\"crop\"]\n",
    ").merge(\n",
    "    climate_results[[\"crop\",\"beta_temp\"]],\n",
    "    on=\"crop\"\n",
    ")\n",
    "\n",
    "high_risk = high_risk[\n",
    "    (high_risk[\"prod_flag\"] != \"growing\") &\n",
    "    (high_risk[\"yield_flag\"] != \"growing\") &\n",
    "    (high_risk[\"beta_temp\"] < 0)\n",
    "]\n",
    "\n",
    "high_risk.sort_values(\"prod_pct_per_year\").head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be64049-80ef-4220-ab18-5e953833fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High risk regions and crops\n",
    "\n",
    "risk_plot = high_risk.groupby([\"region\",\"crop\"]).size().reset_index(name=\"n\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.barplot(\n",
    "    data=risk_plot,\n",
    "    x=\"region\",\n",
    "    y=\"n\",\n",
    "    hue=\"crop\"\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Number of high-risk country–crop pairs\")\n",
    "plt.title(\"Regions Facing Production Shortfalls\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29158092-6ce8-49a7-8353-f04cd9c76770",
   "metadata": {},
   "source": [
    "Southeast Asia and Sub-Saharan Africa face the highest production shortfalls at present, with lower levels of risk in Central Ameriaca, East Asia, Europe, North Africa, North America, South America, and South Asia.  The Middle East and Oceania do not currently have any high-risk country_crop pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f97c7-ffd5-42a8-8b5c-ea5eb00591ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of yield growth across regions\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=yield_trends,\n",
    "    x=\"region\",\n",
    "    y=\"yield_pct_per_year\"\n",
    ")\n",
    "\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", label=\"Zero growth\")\n",
    "plt.axhline(2, color=\"gray\", linestyle=\":\", label=\"Stagnation threshold\")\n",
    "\n",
    "plt.ylabel(\"Yield growth (% per year)\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.title(\"Distribution of Yield Growth Rates by Region (2015–2023)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d99db-207f-4e10-98ef-cd78a850b928",
   "metadata": {},
   "source": [
    "Except for N America,the Middle East and Oceania, all regions have at least one countriey with zero growth or stagnating growth.\n",
    "\n",
    "Only Central America has a mean yield growth that is below zero growth.  The 25th percentile of South Asia, Southeast Asia, Sub-Saharan Africa all lie at or below zero growth.\n",
    "\n",
    "Median yield growth in South Asia, Southeast Asia, Sub-Saharan Africa, South America, and North Africa are all in stagnation (greater than 0 and less than 2%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5f034-9d25-4234-acd1-771c3e645153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 year horizon and index yields for analysis\n",
    "\n",
    "HORIZON = 10\n",
    "\n",
    "proj = yield_trends.copy()\n",
    "\n",
    "proj[\"yield_index_0\"] = 100\n",
    "\n",
    "proj[\"yield_index_future\"] = (\n",
    "    proj[\"yield_index_0\"]\n",
    "    * (1 + proj[\"yield_pct_per_year\"] / 100) ** HORIZON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99f2ce-b44f-4452-9958-70b128f5e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify criteria to flag declining and stagnating yields\n",
    "\n",
    "proj[\"yield_risk_flag\"] = np.select( [ proj[\"yield_index_future\"] < 95, proj[\"yield_index_future\"] < 105 ], [\"declining\",\"stagnating\"], default=\"growing\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422a99a-da97-49bd-a5d4-9d4baad04f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_future_risk = (\n",
    "    proj\n",
    "      .groupby([\"region\",\"crop\",\"yield_risk_flag\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"n\")\n",
    ")\n",
    "\n",
    "region_future_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff6cc4-a7f1-4035-a085-ab62847a5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_only = (\n",
    "    region_future_risk\n",
    "      .groupby([\"region\",\"yield_risk_flag\"], as_index=False)\n",
    "      .agg(n=(\"n\",\"sum\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706e9c1-5410-4e4a-acb2-fa446acb0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = region_only.pivot_table(\n",
    "    index=\"region\",\n",
    "    columns=\"yield_risk_flag\",\n",
    "    values=\"n\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "pivot = pivot[[\"declining\",\"stagnating\"]]\n",
    "pivot_nonzero = pivot.loc[pivot.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2ae55-c7da-4f6e-9dc4-3880a0851a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_nonzero.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(10,6)\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Number of country–crop pairs\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.title(\"Projected Yield Risk Under Trend Continuation (10-year horizon)\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67c7aa-0c7e-4fa3-9ff0-c56b2c8a15ab",
   "metadata": {},
   "source": [
    "If trends continue, Sub-Saharan Africa and Southeast Asia both have 9 country_crop pairs that will be in declining or stagnating states. \n",
    "\n",
    "On the other end of the spectrum, the Middle East, Oceania and North America would not have any crop_country pairs in decline or stagnating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b236bc-2589-4070-97c1-e6dc1e24c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot growth decomposed by harvest area expansion\n",
    "\n",
    "# Compute regional averages\n",
    "region_decomp_plot = (\n",
    "    decomp.groupby([\"region\",\"crop\"], as_index=False)\n",
    "          .agg(\n",
    "              yield_contrib=(\"dln_yield\",\"mean\"),\n",
    "              area_contrib=(\"dln_area\",\"mean\")\n",
    "          )\n",
    ")\n",
    "\n",
    "crop_to_plot = region_decomp_plot[\"crop\"].iloc[0]\n",
    "\n",
    "plot_df = region_decomp_plot[region_decomp_plot[\"crop\"] == crop_to_plot]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.bar(plot_df[\"region\"], plot_df[\"yield_contrib\"], label=\"Yield contribution\")\n",
    "plt.bar(\n",
    "    plot_df[\"region\"],\n",
    "    plot_df[\"area_contrib\"],\n",
    "    bottom=plot_df[\"yield_contrib\"],\n",
    "    label=\"Area contribution\"\n",
    ")\n",
    "\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.ylabel(\"Production change (%)\")\n",
    "plt.title(f\"Production Growth Decomposition (2015–2023): {crop_to_plot}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5c9b3-0d32-46bc-88e5-955a1169d234",
   "metadata": {},
   "source": [
    "Expanding or contracting the area harvested is a significant driver of production growth or loss, as shown by the orange above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f271f-f81f-4307-bdfe-eaa9f264badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate sensitivity by crop\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.barplot(\n",
    "    data=climate_results.sort_values(\"beta_temp\"),\n",
    "    x=\"beta_temp\",\n",
    "    y=\"crop\"\n",
    ")\n",
    "\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Effect of +1°C temperature anomaly on yield (log points)\")\n",
    "plt.ylabel(\"Crop\")\n",
    "plt.title(\"Temperature Sensitivity of Crop Yields\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b15c83-81e6-44d2-9325-746d90f6c84c",
   "metadata": {},
   "source": [
    "Rice has the greatest negative yield response to a 1-degree rise in temperature (C), followed by maize and soybeans.  Interestingly, the data suggests wheat has a positive yield response to a 1-degree rise in temp (C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935bfda-d6ef-420f-b933-eb3dbc234125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average yield growth by income group\n",
    "income_trends = (\n",
    "    yield_trends\n",
    "      .groupby([\"income_group\",\"crop\"], as_index=False)\n",
    "      .agg(\n",
    "          mean_yield_growth=(\"yield_pct_per_year\",\"mean\"),\n",
    "          median_yield_growth=(\"yield_pct_per_year\",\"median\"),\n",
    "          n=(\"country_id\",\"nunique\")\n",
    "      )\n",
    ")\n",
    "\n",
    "income_trends.sort_values([\"crop\",\"mean_yield_growth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9d2e9-1f59-4ef7-a341-c85327a3d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average yield growth by income group\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.barplot(\n",
    "    data=income_trends,\n",
    "    x=\"income_group\",\n",
    "    y=\"mean_yield_growth\",\n",
    "    hue=\"crop\"\n",
    ")\n",
    "\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.ylabel(\"Mean yield growth (% per year)\")\n",
    "plt.xlabel(\"Income group\")\n",
    "plt.title(\"Average Yield Growth by Development Stage\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24ecf1-7f4b-450a-9666-9bc3e858bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data to plot annual yield by income group\n",
    "income_yields = (\n",
    "    df_4\n",
    "      .groupby([\"income_group\",\"year\"], as_index=False)\n",
    "      .agg(\n",
    "          median_yield=(\"yield_kg_ha\",\"median\")\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ccc54-8854-4c2b-b36f-146ec92df418",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_wide = income_yields.pivot(\n",
    "    index=\"year\",\n",
    "    columns=\"income_group\",\n",
    "    values=\"median_yield\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c2790-597b-473d-ac52-c7423a470819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot yearly yield by income group\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for col in income_wide.columns:\n",
    "    plt.plot(\n",
    "        income_wide.index,\n",
    "        income_wide[col],\n",
    "        label=col\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Median yield (kg per hectare)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(\"Yield Trajectories by Income Group\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5cd91-a148-47a8-bdac-5c6907984b02",
   "metadata": {},
   "source": [
    "Median yields are higher as income group progresses -- that is, low income countries have the lowest median yield and high income countries have the highest median yield.\n",
    "\n",
    "For the most part, high, upper-middle, and lower-middle income group yields move in tandem, except from 2022-2023 where the high income group yields dropped and upper-middle and lower-middle group yields rose.\n",
    "\n",
    "From 2019 to 2020, the gap between low and lower-middle income groups closed to about 0, before reversing trend with 2023's gap returning to approximately 2018 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73eb96-bd85-48b9-ae6e-9a29d499fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify heat sensitive crops\n",
    "heat_sensitive = climate_results[\n",
    "    climate_results[\"beta_temp\"] < 0\n",
    "][[\"crop\",\"beta_temp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9b7c6-552f-4a3b-aaec-ddc0ac66c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress temperature on year and identify trends by country\n",
    "def temp_trend(group):\n",
    "    g = group.dropna(subset=[\"avg_temp_mean_c\",\"year\"])\n",
    "    if len(g) < 8:\n",
    "        return np.nan\n",
    "    m = smf.ols(\"avg_temp_mean_c ~ year\", data=g).fit()\n",
    "    return m.params[\"year\"]\n",
    "\n",
    "temp_trends = (\n",
    "    df_4\n",
    "      .groupby(\"country_id\")\n",
    "      .apply(temp_trend)\n",
    "      .reset_index(name=\"temp_trend_c_per_year\")\n",
    ")\n",
    "\n",
    "df_4 = df_4.merge(temp_trends, on=\"country_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a47f9e-d70b-4880-8d37-05bd3d4c369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge climate-sensitive crop data with country warming trends\n",
    "climate_risk = yield_trends.merge(\n",
    "    heat_sensitive,\n",
    "    on=\"crop\",\n",
    "    how=\"inner\"\n",
    ").merge(\n",
    "    temp_trends,\n",
    "    on=\"country_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5f2ef-cb13-4cb9-9a12-ea80324cfd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify climate-affected country_crop combinations\n",
    "affected = climate_risk[\n",
    "    (climate_risk[\"yield_flag\"].isin([\"stagnating\",\"declining\"])) &\n",
    "    (climate_risk[\"temp_trend_c_per_year\"] > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e74a6-de06-4918-ba3d-1aa3d3884690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region\n",
    "affected_region = (\n",
    "    affected\n",
    "      .groupby([\"region\",\"crop\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"n_countries\")\n",
    "      .sort_values(\"n_countries\", ascending=False)\n",
    ")\n",
    "\n",
    "affected_region.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c310c3-c902-4a82-b159-e3b6def7000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.barplot(\n",
    "    data=affected_region,\n",
    "    x=\"region\",\n",
    "    y=\"n_countries\",\n",
    "    hue=\"crop\"\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Number of affected countries\")\n",
    "plt.title(\"Countries Showing Evidence of Climate-Related Yield Impacts\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149a369-990e-4d1d-beef-298dce3a6d56",
   "metadata": {},
   "source": [
    "South Asia, with 5 country_crop combinations affected by Climate Change (defined as an increase in temperature having a negative impact on yeild), leads all regions, with Central America following with 3 affected country_crop combinations.  Otherwise, climate change affects are largely limited, with Maize impacted in one country in East Asia, North Africa, Europe and Sub-Saharan Africa, and Rice affected in one conutry in Southeast Asia.  Consistent with the above results on how a 1-degree increase affects each crop, negative yields in response to temperature rise are not observed for wheat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fre521d]",
   "language": "python",
   "name": "conda-env-fre521d-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
